{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intent_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUUjcfs4xBGz"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qX8WhjTelET",
        "outputId": "32435368-d544-4f60-ea20-406dcd182b50"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyCU1R9f7e7w"
      },
      "source": [
        "import transformers as ppb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "u8lRi2Lpim8W",
        "outputId": "d563f349-aff9-4eb2-eadd-f25b328abc23"
      },
      "source": [
        "df = pd.DataFrame(columns = ['sentence','class'])\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [sentence, class]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pu-6tUNWf4k8",
        "outputId": "72091263-e56d-43ef-b183-e07b67bab604"
      },
      "source": [
        "with open('/content/drive/MyDrive/data_chatbot.txt', 'r') as f:\n",
        "    lst = []\n",
        "    num=0\n",
        "    for line in f:\n",
        "        if line=='\\n':\n",
        "            lst = list(set(lst))\n",
        "            df1 = pd.DataFrame({'sentence':lst,'class':[num]*len(lst)})\n",
        "            df = pd.concat([df, df1]).reset_index(drop = True)\n",
        "            lst=[]\n",
        "            num+=1\n",
        "        else:\n",
        "            line = line.lower()\n",
        "            lst.append(line[:-1])\n",
        "df1 = pd.DataFrame({'sentence':lst,'class':[num]*len(lst)})\n",
        "df = pd.concat([df, df1]).reset_index(drop = True)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>какие условия по кредитам на покупку машины?</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>что есть в наличии?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>какое количество функций ты в себя включаешь?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>какие машины предлагаете?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>каков функционал вашей компании?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         sentence class\n",
              "0    какие условия по кредитам на покупку машины?     3\n",
              "1                             что есть в наличии?     4\n",
              "2  какое количество функций ты в себя включаешь?      1\n",
              "3                       какие машины предлагаете?     4\n",
              "4                каков функционал вашей компании?     2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFfi2-v6iIo5"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'DeepPavlov/rubert-base-cased')\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuRg764W7hEm",
        "outputId": "401284a2-eaad-4bc6-82c6-d8cf7d9e33d3"
      },
      "source": [
        "tokenized = df['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [101, 19201, 16132, 1516, 52189, 1469, 32170, ...\n",
              "1              [101, 1997, 6818, 845, 25097, 166, 102]\n",
              "2    [101, 25206, 9595, 15535, 4609, 845, 6678, 568...\n",
              "3            [101, 19201, 14798, 19462, 842, 166, 102]\n",
              "4    [101, 2739, 1388, 117086, 90754, 852, 6597, 16...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulmL7YcX752d",
        "outputId": "6ad76134-f353-4ca1-fe27-cf595c03d8d8"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "np.array(padded).shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8al6ahrZ8uFP",
        "outputId": "90b48566-8941-4ded-fa35-f6f8687c68f1"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK5Vq03h86Om"
      },
      "source": [
        "input_ids = torch.tensor(padded)\n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLrk5E5V9A4S"
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "labels = df['class']\n",
        "labels=labels.astype('int')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tj4gwGN9fY4",
        "outputId": "510b11ba-fcf6-4eeb-a19e-6986b417ab3c"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, labels,test_size=0.2)\n",
        "lr_clf = LogisticRegression(C=1,multi_class='ovr',max_iter=300,random_state=41)\n",
        "lr_clf.fit(x_train, y_train)\n",
        "lr_clf.score(x_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9622641509433962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmJR2oMtsn5r"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "params = {'n_estimators': 500,\n",
        " 'reg_alpha': 0.05,\n",
        " 'reg_lambda': 9,\n",
        " #'colsample_bytree': 0.3,\n",
        " 'eval_metric':'merror',\n",
        " 'subsample': 0.8,\n",
        " 'learning_rate': 0.1,\n",
        " 'max_depth': 5,\n",
        " 'num_leaves': 20,\n",
        " 'random_state': 42,\n",
        " 'min_child_samples': 47,\n",
        " 'min_data_per_groups': 96,\n",
        " 'tree_method': \"gpu_hist\",\n",
        " \"gpu_id\": 0}\n",
        "\n",
        "model_xgb = XGBClassifier(**params)\n",
        "model_xgb.fit(x_train,y_train, eval_set=[(x_test,y_test)], verbose=True,early_stopping_rounds=200)\n",
        "y_pred = model_xgb.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDs2_Lw01HV3",
        "outputId": "69785efe-84df-4a29-c060-f5f62ecc0655"
      },
      "source": [
        "y_pred = model_xgb.predict(x_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9245283018867925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP1viZgcsxQI"
      },
      "source": [
        "## Try bert-only classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afoka1rdyGQr"
      },
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizerFast\n",
        "from transformers import Trainer, TrainingArguments, AdamW"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqEl1w-B0RfN"
      },
      "source": [
        "class CustomBERTModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomBERTModel, self).__init__()\n",
        "\n",
        "    self.num_labels = 5\n",
        "    self.weights = None\n",
        "    self.bert = BertModel.from_pretrained('DeepPavlov/rubert-base-cased')\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.out = torch.nn.Linear(768, self.num_labels)\n",
        "    # self.softmax = torch.nn.Softmax(19)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
        "    res = self.bert(\n",
        "          input_ids, \n",
        "          attention_mask=attention_mask,\n",
        "          token_type_ids=token_type_ids\n",
        "    )\n",
        "\n",
        "    sequence_output = self.dropout(res['pooler_output'])\n",
        "\n",
        "    logits = self.out(sequence_output)\n",
        "\n",
        "    outputs = (logits, )\n",
        "\n",
        "    if labels is not None:\n",
        "      loss_fct = torch.nn.CrossEntropyLoss(weight=self.weights)\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "      outputs = (loss,) + outputs\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8spxsAyy9dJ"
      },
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('DeepPavlov/rubert-base-cased')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra-ZtXuszdoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a622f73-ced6-4a3c-871b-a6904d351cf6"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.sentence.tolist(), df['class'].tolist(),test_size=0.2)\n",
        "\n",
        "train_encodings = tokenizer(x_train, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(x_test, truncation=True, padding=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbABS-rG0RI6"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Dataset(train_encodings, y_train)\n",
        "val_dataset = Dataset(val_encodings, y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY5bh4gN1T3H"
      },
      "source": [
        "model = CustomBERTModel()\n",
        "\n",
        "for param in model.bert.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC7jhL3_ylJj"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=20,\n",
        "    logging_strategy='epoch',\n",
        "    evaluation_strategy='epoch',\n",
        "    output_dir=f'tmp/out',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=f'tmp/logging',\n",
        "    logging_steps=100,\n",
        "    # save_steps=100,\n",
        "    metric_for_best_model=\"eval_loss\", \n",
        "    lr_scheduler_type='cosine_with_restarts',\n",
        "    learning_rate=1e-2\n",
        ")\n",
        "\n",
        "model.train()\n",
        "model.to('cuda:0')\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "LQYw6TO72VNZ",
        "outputId": "92405577-2408-41f3-862f-9a1829e3a567"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model\n",
        ")\n",
        "\n",
        "y_pred = trainer.predict(val_dataset).predictions.argmax(axis=1).tolist()\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 53\n",
            "  Batch size = 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.8867924528301887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Lm7f1k3xzw"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}